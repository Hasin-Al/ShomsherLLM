# ğŸ‰ ShomsherLLM

ShomsherLLM is a custom-built **Large Language Model (LLM)** designed with advanced architectural optimizations for **efficient training** and **scalable inference**.  

It combines **Decoupled Rotary Positional Encoding (DeRoPE)**, **KV Cache Compression**, and a **Mixture of Experts (MoE)** feedforward layer with **hybrid normalization strategies** for robust performance.  

---

## âœ¨ Features

- ğŸ“ **Decoupled Rotary Positional Encoding (DeRoPE)**  
  Improves positional awareness and stability for long-context sequences.  

- âš¡ **KV Cache Compression**  
  Enables fast autoregressive decoding while reducing memory usage.  

- ğŸ”„ **Hybrid Normalization**  
  - **Pre-Norm:** Layer Normalization (using variance & standard deviation).  
  - **Post-Norm:** RMS Normalization (RMSNorm).  

- ğŸ§© **Mixture of Experts (MoE) Feedforward**  
  Increases model capacity without linear parameter growth.  

- ğŸ”¤ **BPE Tokenizer**  
  Efficient subword tokenization, supports multilingual datasets.  

---

## ğŸ“‚ Repository Structure

```bash
â”œâ”€â”€ main.py             # Entry point for training/inference
â”œâ”€â”€ train.py            # Training loop
â”œâ”€â”€ model.py            # Core ShomsherLLM model
â”œâ”€â”€ DeRoPE.py            # Decoupled Rotatry Positional encoding class
â”œâ”€â”€ MultiHeadLatentAttention.py            # KV caching attetniton class
â”œâ”€â”€ TransformerBlock.py            # Transformer class
â”œâ”€â”€ TrainTokenizer.py            # To train our BPE tokenizer
â”œâ”€â”€ TextGeneration.py            # To generate text using our trained model
â”œâ”€â”€ neededclass.py      # Supporting classes:
â”‚                       #    - MoE feedforward
â”‚                       #    - Normalization layers
â”‚                       #    - SwiGLU
â”‚                       #  
â”œâ”€â”€ DataClean.py        # Data cleaning & preprocessing
â”œâ”€â”€ tokenizer/          # BPE tokenizer files
â”‚   â””â”€â”€ bpe_tokenizer.json
â”œâ”€â”€ models/             # Saved checkpoints
â”‚   â””â”€â”€ model_latest.pt
â”œâ”€â”€ ShamsherLLM.ipynb            # Core ShomsherLLM notebook
â””â”€â”€ README.md           # Project documentation

